{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '.../model_iot.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9c1f8e0be205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalling_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9c1f8e0be205>\u001b[0m in \u001b[0;36mopen_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mPARAMS_PATH\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;34m\".../model_iot.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPARAMS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mmodelParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"modelParams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spParams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '.../model_iot.yaml'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import numpy\n",
    "import os\n",
    "import yaml\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from nupic.algorithms.spatial_pooler import SpatialPooler\n",
    "from nupic.algorithms.temporal_memory import TemporalMemory\n",
    "from nupic.encoders.multi import  MultiEncoder\n",
    "from  nupic.encoders.scalar import ScalarEncoder\n",
    "from nupic.encoders.category import CategoryEncoder\n",
    "from nupic.algorithms.sdr_classifier import  SDRClassifier\n",
    "from time import  time\n",
    "import json\n",
    "import urllib2\n",
    "import capnp\n",
    "from nupic.algorithms.spatial_pooler import SpatialPooler\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "class Prediction():\n",
    "    \n",
    "    def __init__(self):\n",
    "        #Baseline for lesarning\n",
    "        self.sink_tap = []\n",
    "        self.shower = []\n",
    "        self.toilet = []\n",
    "        self.pressure = []\n",
    "        self.flow_rate = [] \n",
    "        self.encoding = [] \n",
    "        self.val_massive = [] \n",
    "        self.pressure = []\n",
    "        self.events = dict()\n",
    "        self.baseline = []\n",
    "        self.encoding_csv = []\n",
    "        self.flow = list()\n",
    "        #Result information\n",
    "        self.classifier_counter = 0 \n",
    "        self.event = []\n",
    "        self.result_testing = [0]\n",
    "        self.result_testing1 = [0]\n",
    "        self.result_testing2 = [0]\n",
    "        self.baseline_test = []\n",
    "        self.event10 = []\n",
    "        self.length = 0 \n",
    "        self.filename1  = datetime.datetime.strftime(datetime.datetime.now(), \"%Y.%m.%d_%H:%M:%S\")\n",
    "        self.b = 0\n",
    "        self.t = 0\n",
    "        #Array for divorce wmId\n",
    "        self.list_id = [] \n",
    "        self.flag = 0 \n",
    "        self.len = 0\n",
    "        #Baseline for real data \n",
    "        self.wmId  = []\n",
    "        self.pres1 = []\n",
    "        self.wmId  = []\n",
    "        self.wmId1 = []\n",
    "        self.id    = []\n",
    "        self.flow1 = []\n",
    "        self.time1 = []\n",
    "        self.length_list_id = 0\n",
    "\n",
    "        self.label = []\n",
    "        self.labels = []\n",
    "        self.pred_3 = []\n",
    "        self.pred_2 = []\n",
    "        self.pred_1 = []\n",
    "        \n",
    "    def parse_dataset(self):\n",
    "        self.event_all = []\n",
    "        self.ev = dict()\n",
    "        INPUT_DATSET = (\".../real_dataset2.csv\")\n",
    "        with open(INPUT_DATSET) as fin:\n",
    "            reader = csv.reader(fin, delimiter=',')\n",
    "            reader.next()\n",
    "            reader.next()\n",
    "            reader.next()\n",
    "            \n",
    "        \n",
    "            for row in reader:\n",
    "                self.pressure.append(float(row[1]))\n",
    "                self.flow_rate.append(float(row[2]))\n",
    "                self.event.append(row[3])\n",
    "            for tt in range(0,20000):\n",
    "                self.event_all.append(self.event[tt])\n",
    "            kr = 0    \n",
    "            for cur in xrange(len(self.event_all)): # cur - current self.infex in massive event\n",
    "                kr = map(int,self.event[cur].split(\",\")) #  Parse string\n",
    "                for tir in xrange(len(kr)):\n",
    "                    additional_sink_tap = 0\n",
    "                    additional_toilet = 0\n",
    "                    additional_shower = 0 \n",
    "                    if kr[tir] == 2: \n",
    "                        additional_toilet = 1\n",
    "                    if kr[tir] == 1: \n",
    "                        additional_sink_tap = 1\n",
    "                    if kr[tir] == 3: \n",
    "                        additional_shower = 1\n",
    "\t\t\t\t\t\t\n",
    "                self.ev['additional_toilet'] = additional_toilet\n",
    "                self.ev['additional_shower'] = additional_shower\n",
    "                self.ev['additional_sink_tap'] = additional_sink_tap\n",
    "    \n",
    "                if tir == 0:\n",
    "                    self.events['toilet'] = additional_toilet\n",
    "                    self.events['shower']  = additional_shower \n",
    "                    self.events['sink_tap'] = additional_sink_tap\n",
    "\n",
    "                self.sink_tap.append(self.events['sink_tap'])\n",
    "                self.shower.append(self.events['shower'])\n",
    "                self.toilet.append(self.events['toilet'])\n",
    "\n",
    "    def baseline_learning (self,left_r):\n",
    "        self.val_massive.append(self.pressure[left_r])\n",
    "        if(len(self.val_massive)>1):\n",
    "            for i in range(2,len(self.pressure)):\n",
    "                self.sum_sred = math.ceil(sum(self.val_massive)/len(self.val_massive))\n",
    "                enc_value = (self.sum_sred - self.val_massive[-1])\n",
    "                sq = math.sqrt(enc_value**2)\n",
    "\n",
    "                if ((self.flow_rate[left_r + i-1] - self.flow_rate[left_r + i - 2])<0.5 and (self.flow_rate[left_r + i-2] - self.flow_rate[left_r + i - 1])<0.5):\n",
    "                    print \"Flow_rate-1\", self.flow_rate[left_r + i - 1] - self.flow_rate[left_r + i - 2]\n",
    "                else:\n",
    "                    del self.val_massive[-1]\n",
    "                    try:\n",
    "                        self.sum_sred_1 = sum(self.val_massive) / len(self.val_massive)\n",
    "                    except ZeroDivisionError:\n",
    "                        pass\n",
    "                    for vts in range(0, len(self.val_massive)):\n",
    "                        positive_value = self.sum_sred_1 - self.val_massive[vts]\n",
    "                        self.encoding.append(round(positive_value, 2))\n",
    "                        self.baseline.append(round(self.sum_sred_1, 2))\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            self.val_massive.append(self.pressure[left_r+1])\n",
    "\n",
    "            for i in xrange(2,len(self.pressure)):\n",
    "                self.sum_sred = math.ceil(sum(self.val_massive) / len(self.val_massive))\n",
    "                enc_value = self.sum_sred - self.val_massive[-1]\n",
    "                sq = math.sqrt(enc_value**2)\n",
    "\n",
    "                if ((self.flow_rate[left_r + i - 1] - self.flow_rate[left_r + i - 2]) < 0.5 and (self.flow_rate[left_r + i - 2] - self.flow_rate[left_r + i - 1]) < 0.5):\n",
    "                    self.val_massive.append(self.pressure[left_r+i])\n",
    "                else:\n",
    "                    del  self.val_massive[-1]\n",
    "                    try:\n",
    "                        self.sum_sred_1 = sum(self.val_massive) / len(self.val_massive)\n",
    "                    except ZeroDivisionError:\n",
    "                        pass\n",
    "\n",
    "                    for vts in range(0, len(self.val_massive)):\n",
    "                        positive_value = self.sum_sred_1 - self.val_massive[vts]\n",
    "                        self.encoding.append(round(positive_value, 2))\n",
    "                        self.baseline.append(round(self.sum_sred_1, 2))\n",
    "                    break\n",
    "    \n",
    "        self.index = i +left_r\n",
    "        self.val_massive = []\n",
    "\n",
    "    def calling_diff(self):\n",
    "        ty = 1\n",
    "        self.baseline_learning(ty)\n",
    "        while (self.index <19980):\n",
    "            self.baseline_learning(self.index-1)\n",
    "        headers = (\"flow\",\"event\",\"sink_tap\",\"toilet\",\"shower\",\"encoding\",\"baseline\",\"pressure\")\n",
    "        type = (\"float\",\"int\",\"int\",\"int\",\"int\",\"float\",\"float\",\"float\")\n",
    "        meta = (\" \",\" \",\" \",\" \",\" \")\n",
    "        with open('test.csv', 'w') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow(headers)\n",
    "            csv_writer.writerow(type)\n",
    "            csv_writer.writerow(meta)\n",
    "            for pot in range(0, 19970):\n",
    "                csv_writer.writerow([self.flow_rate[pot],self.event[pot],self.sink_tap[pot],self.toilet[pot],self.shower[pot],self.encoding[pot],self.baseline[pot],self.pressure[pot]])\n",
    "    \n",
    "    def open_params(self):\n",
    "        \n",
    "        PARAMS_PATH =  (\".../model_iot.yaml\")\n",
    "        with open(PARAMS_PATH, \"r\") as f:\n",
    "            modelParams = yaml.safe_load(f)[\"modelParams\"]   \n",
    "            self.spParams = modelParams[\"spParams\"]\n",
    "            self.tmParams = modelParams[\"tmParams\"]\n",
    "            self.clParams = modelParams[\"clParams\"]\n",
    "        self.sink_tap_Encoder = ScalarEncoder(name=\"sink_tap\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "        self.toilet_Encoder = ScalarEncoder(name=\"toilet\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "        self.shower_Encoder = ScalarEncoder(name=\"shower\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "\n",
    "        self.baselineEncoder = ScalarEncoder(name = \"baseline\",w = 21, n = 2625,minval= 47,maxval=75,forced= True)\n",
    "        self.pressEncoder = ScalarEncoder(name = \"pressure\",w = 21, n = 462,minval= 44,maxval=66,forced= True)\n",
    "\n",
    "        self.flowEncoder = ScalarEncoder(name=\"flow\", w=15, n=1050, minval=0, maxval=6,forced = True)\n",
    "        self.encodingWidth = (self.sink_tap_Encoder.getWidth()+self.flowEncoder.getWidth()+self.baselineEncoder.getWidth()\n",
    "                                +self.toilet_Encoder.getWidth()+self.flowEncoder.getWidth()+self.baselineEncoder.getWidth()\n",
    "                                +self.shower_Encoder.getWidth()+self.flowEncoder.getWidth()+self.baselineEncoder.getWidth())\n",
    "\n",
    "        self.sp = SpatialPooler(\n",
    "            inputDimensions=(self.encodingWidth,),\n",
    "            columnDimensions=(self.spParams[\"columnCount\"],),\n",
    "            potentialPct=self.spParams[\"potentialPct\"],\n",
    "            potentialRadius=self.encodingWidth,\n",
    "            globalInhibition=self.spParams[\"globalInhibition\"],\n",
    "            localAreaDensity=self.spParams[\"localAreaDensity\"],\n",
    "            numActiveColumnsPerInhArea=self.spParams[\"numActiveColumnsPerInhArea\"],\n",
    "            synPermInactiveDec=self.spParams[\"synPermInactiveDec\"],\n",
    "            synPermActiveInc=self.spParams[\"synPermActiveInc\"],\n",
    "            synPermConnected=self.spParams[\"synPermConnected\"],\n",
    "            boostStrength=self.spParams[\"boostStrength\"],\n",
    "            seed=self.spParams[\"seed\"],\n",
    "            wrapAround=True\n",
    "        )\n",
    "\n",
    "        self.tm = TemporalMemory(\n",
    "            columnDimensions=(self.tmParams[\"columnCount\"],),\n",
    "            cellsPerColumn=self.tmParams[\"cellsPerColumn\"],\n",
    "            activationThreshold=self.tmParams[\"activationThreshold\"],\n",
    "            initialPermanence=self.tmParams[\"initialPerm\"],\n",
    "            connectedPermanence=self.spParams[\"synPermConnected\"],\n",
    "            minThreshold=self.tmParams[\"minThreshold\"],\n",
    "            maxNewSynapseCount=self.tmParams[\"newSynapseCount\"],\n",
    "            permanenceIncrement=self.tmParams[\"permanenceInc\"],\n",
    "            permanenceDecrement=self.tmParams[\"permanenceDec\"],\n",
    "            predictedSegmentDecrement=self.tmParams[\"predictedSegmentDecrement\"],\n",
    "            maxSegmentsPerCell=self.tmParams[\"maxSegmentsPerCell\"],\n",
    "            maxSynapsesPerSegment=self.tmParams[\"maxSynapsesPerSegment\"],\n",
    "            seed=self.tmParams[\"seed\"]\n",
    "        )\n",
    "\n",
    "        self.classifier = SDRClassifier(\n",
    "            steps  = [1],alpha=self.clParams[\"alpha\"],verbosity= self.clParams[\"verbosity\"]\n",
    "        )\n",
    "        self.classifier1 = SDRClassifier(\n",
    "            steps  = [1],alpha=self.clParams[\"alpha\"],verbosity= self.clParams[\"verbosity\"]\n",
    "        )\n",
    "        self.classifier2 = SDRClassifier(\n",
    "            steps  = [1],alpha=self.clParams[\"alpha\"],verbosity= self.clParams[\"verbosity\"]\n",
    "        )\n",
    "\n",
    "    def runLearning(self,numRecords):\n",
    "        learning_time = time()\n",
    "        with open(\"test.csv\", \"r\") as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            headers = reader.next()\n",
    "            reader.next()\n",
    "            reader.next()\n",
    "            learning_progress = wg.IntProgress(min = 0,max = numRecords,value = 0,description = \" Learning loading\",step = 1,bar_style='info')\n",
    "            display(learning_progress)\n",
    "            for count, record in enumerate(reader):\n",
    "                #print \"Count\",count\n",
    "                learning_progress.value = count\n",
    "                if count >= numRecords: break\n",
    "\n",
    "                # Convert data value string into float.\n",
    "                self.sink_tap_value = float(record[2]) # device 1\n",
    "                self.toilet_value = float(record[3]) #device 2\n",
    "                self.shower__value = float(record[4]) # device 3\n",
    "\n",
    "                 # event_value_7 = float(record[8]) # device 7\n",
    "                self.baseline_all = float(record[6])\n",
    "                self.flow_value  = float(record[0])\n",
    "                # To encode, we need to provide zero-filled numpy arrays for the encoders\n",
    "                # to populate.\n",
    "                self.eventBits = numpy.zeros(self.sink_tap_Encoder.getWidth())\n",
    "                self.eventBits_2 = numpy.zeros(self.toilet_Encoder.getWidth())\n",
    "                self.eventBits_3 = numpy.zeros(self.shower_Encoder.getWidth())\n",
    "\n",
    "                self.baseline_Bits = numpy.zeros(self.baselineEncoder.getWidth())\n",
    "                self.flowBits = numpy.zeros(self.flowEncoder.getWidth())\n",
    "\n",
    "                 # Now we call the encoders to create bit representations for each value.\n",
    "                self.sink_tap_Encoder.encodeIntoArray(self.sink_tap_value,self.eventBits)\n",
    "                self.toilet_Encoder.encodeIntoArray(self.toilet_value,self.eventBits_3)\n",
    "                self.shower_Encoder.encodeIntoArray(self.shower__value,self.eventBits_2) \n",
    "\n",
    "                self.baselineEncoder.encodeIntoArray(self.baseline_all,self.baseline_Bits)\n",
    "                self.flowEncoder.encodeIntoArray(self.flow_value,self.flowBits)\n",
    "\n",
    "                # Concatenate all these encodings into one large encoding for Spatial\n",
    "                 # Pooling.\n",
    "                self.encoding = numpy.concatenate(\n",
    "                    [self.eventBits,self.flowBits,self.baseline_Bits,self.eventBits_2,self.flowBits,self.baseline_Bits,self.eventBits_3,self.flowBits,self.baseline_Bits]\n",
    "                )\n",
    "\n",
    "                # Create an array to represent active columns, all initially zero. This\n",
    "                 # will be populated by the compute method below. It must have the same\n",
    "                 # dimensions as the Spatial Pooler.\n",
    "                self.activeColumns = numpy.zeros(self.spParams[\"columnCount\"])\n",
    "                 # activeColumns1 = numpy.zeros(self.spParams[\"columnCount\"])\n",
    "\n",
    "                 # Execute Spatial Pooling algorithm over input space.\n",
    "\n",
    "                self.sp.compute(self.encoding,True,self.activeColumns)\n",
    "\n",
    "                # sp.compute(encoding1, True, activeColumns)\n",
    "\n",
    "                self.activeColumnIndices = numpy.nonzero(self.activeColumns)[0]\n",
    "\n",
    "                 # Execute Temporal Memory algorithm over active mini-columns.\n",
    "                self.tm.compute(self.activeColumnIndices, learn=True)\n",
    "\n",
    "                self.activeCells = self.tm.getActiveCells()\n",
    "\n",
    "                # Get the bucket info for this input value for classification.\n",
    "                self.bucketIdx_sink_tap  =  self.sink_tap_Encoder.getBucketIndices(self.sink_tap_value)[0] \n",
    "                self.bucketIdx_toilet = self.toilet_Encoder.getBucketIndices(self.toilet_value)[0]\n",
    "                self.bucketIdx_shower = self.shower_Encoder.getBucketIndices(self.shower__value)[0]\n",
    "\n",
    "                # Run classifier to translate active cells back to scalar value.\n",
    "                self.classifierResult = self.classifier.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ=self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_sink_tap,\n",
    "                        \"actValue\": self.sink_tap_value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "                self.classifierResult1 = self.classifier1.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ=self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_toilet,\n",
    "                        \"actValue\": self.toilet_value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "\n",
    "                self.classifierResult2 = self.classifier2.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ=self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_shower,\n",
    "                        \"actValue\": self.shower__value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "                self.classifier_counter += 1\n",
    "                learning_time_end = time()\n",
    " \n",
    "    def runTesting(self,numRecords):       \n",
    "        testing_time = time()\n",
    "        REAL_DATSET = (\"test.csv\")\n",
    "        with open(REAL_DATSET, \"r\") as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            headers = reader.next()\n",
    "            reader.next()\n",
    "            reader.next()\n",
    "            testing_progress = wg.IntProgress(min = 0,max = numRecords,value = 0,description = \" Testing loading\",step = 1,bar_style='info')\n",
    "            display(testing_progress)\n",
    "            for count, record in enumerate(reader):\n",
    "                testing_progress.value = count\n",
    "                if count >= numRecords: break\n",
    "\n",
    "                # Convert data string into Python date object.\n",
    "                #dateString = datetime.datetime.strptime(record[0], \"%m/%d/%y %H:%M\")\n",
    "                # Convert data value string into float.\n",
    "                self.sink_tap_value = self.result_testing[count]\n",
    "                self.toilet_value = self.result_testing1[count]\n",
    "                self.shower__value = self.result_testing2[count]\n",
    "\n",
    "                self.baseline_all = float(record[6])\n",
    "                self.flow_value  = float(record[0])\n",
    "\n",
    "                # To encode, we need to provide zero-filled numpy arrays for the encoders\n",
    "                # to populate.\n",
    "                self.eventBits = numpy.zeros(self.sink_tap_Encoder.getWidth())\n",
    "                self.eventBits_2 = numpy.zeros(self.toilet_Encoder.getWidth())\n",
    "                self.eventBits_3 = numpy.zeros(self.shower_Encoder.getWidth())\n",
    " \n",
    "                self.flowBits = numpy.zeros(self.flowEncoder.getWidth())\n",
    "                self.baseline_Bits = numpy.zeros(self.baselineEncoder.getWidth())\n",
    "\n",
    "                # Now we call the encoders to create bit representations for each value.\n",
    "                self.sink_tap_Encoder.encodeIntoArray(self.sink_tap_value,self.eventBits)\n",
    "                self.toilet_Encoder.encodeIntoArray(self.toilet_value,self.eventBits_2)\n",
    "                self.shower_Encoder.encodeIntoArray(self.shower__value,self.eventBits_3)\n",
    "\n",
    "                self.baselineEncoder.encodeIntoArray(self.baseline_all,self.baseline_Bits)\n",
    "                self.flowEncoder.encodeIntoArray(self.flow_value,self.flowBits)\n",
    "\n",
    "                # Concatenate all these encodings into one large encoding for Spatial\n",
    "                # Pooling.\n",
    "                self.encoding = numpy.concatenate(\n",
    "                    [self.eventBits,self.flowBits,self.baseline_Bits,self.eventBits_2,self.flowBits,self.baseline_Bits,self.eventBits_3,self.flowBits,self.baseline_Bits]\n",
    "                )\n",
    "    \n",
    "                # Create an array to represent active columns, all initially zero. This\n",
    "                # will be populated by the compute method below. It must have the same\n",
    "                # dimensions as the Spatial Pooler.\n",
    "                self.activeColumns = numpy.zeros(self.spParams[\"columnCount\"])\n",
    "\n",
    "                # Execute Spatial Pooling algorithm over input space.\n",
    "                self.sp.compute(self.encoding, False, self.activeColumns)\n",
    "\n",
    "                self.activeColumnIndices = numpy.nonzero(self.activeColumns)[0]\n",
    "\n",
    "                # Execute Temporal Memory algorithm over active mini-columns.\n",
    "                self.tm.compute(self.activeColumnIndices, learn=False)\n",
    "\n",
    "                self.activeCells = self.tm.getActiveCells()\n",
    "\n",
    "                # Get the bucket info for this input value for classification.\n",
    "                self.bucketIdx_sink_tap  = self.sink_tap_Encoder.getBucketIndices(self.sink_tap_value)[0] \n",
    "                self.bucketIdx_toilet = self.toilet_Encoder.getBucketIndices(self.toilet_value)[0]\n",
    "                self.bucketIdx_shower = self.shower_Encoder.getBucketIndices(self.shower__value)[0]\n",
    "\n",
    "      # Run classifier to translate active cells back to scalar value.\n",
    "                self.classifierResult = self.classifier.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ=self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_sink_tap,\n",
    "                        \"actValue\": self.sink_tap_value\n",
    "                    },\n",
    "                    learn=False,\n",
    "                    infer=True\n",
    "                )\n",
    "\n",
    "                self.classifierResult1 = self.classifier1.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ= self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_toilet,\n",
    "                        \"actValue\": self.toilet_value\n",
    "                    },\n",
    "                    learn=False,\n",
    "                    infer=True\n",
    "                )\n",
    "\n",
    "                self.classifierResult2 = self.classifier2.compute(\n",
    "                    recordNum=self.classifier_counter,\n",
    "                    patternNZ= self.activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": self.bucketIdx_shower,\n",
    "                        \"actValue\": self.shower__value\n",
    "                    },\n",
    "                    learn=False,\n",
    "                    infer=True\n",
    "                )\n",
    "                self.classifier_counter += 1\n",
    "                 # Print the best prediction for 1 step out.\n",
    "                oneStepConfidence, oneStep = sorted(\n",
    "                    zip(self.classifierResult[1], self.classifierResult[\"actualValues\"]),\n",
    "                    reverse=True\n",
    "                )[0]\n",
    "                oneStepConfidence1, oneStep1 = sorted(\n",
    "                    zip(self.classifierResult1[1], self.classifierResult1[\"actualValues\"]),\n",
    "                    reverse=True\n",
    "                )[0]\n",
    "\n",
    "                oneStepConfidence2, oneStep2 = sorted(\n",
    "                    zip(self.classifierResult2[1], self.classifierResult2[\"actualValues\"]),\n",
    "                    reverse=True\n",
    "                )[0]               \n",
    "                testing_time_end = time()\n",
    "                #print \"Time testing\", (testing_time_end - testing_time)\n",
    "\n",
    "                self.result_testing.append(oneStep)\n",
    "                self.result_testing1.append(oneStep1)\n",
    "                self.result_testing2.append(oneStep2)\n",
    "            with open(\"learning_dataset.csv\", 'w') as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                headers = (\"prediction_sink_tap\",\"sink_tap\",\"prediction_toilet\",\"toilet\",\"prediction_shower\",\"shower\",\"encoding\", \"baseline\", \"flow\", \"pressure\")\n",
    "                csv_writer.writerow(headers)\n",
    "                for l in xrange(numRecords) :\n",
    "                    csv_writer.writerow([self.result_testing[l],self.sink_tap[l],self.result_testing1[l],self.toilet[l],self.result_testing2[l],self.shower[l],self.encoding[l], self.baseline[l], self.flow_rate[l], self.pressure[l]])\n",
    "            testing_time_end = time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = Prediction()\n",
    "    test.open_params()\n",
    "    test.parse_dataset()\n",
    "    test.calling_diff()\n",
    "    test.runLearning(200)\n",
    "    test.runTesting(100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
