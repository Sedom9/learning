{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml \n",
    "from nupic.algorithms.spatial_pooler import SpatialPooler\n",
    "from nupic.algorithms.temporal_memory import TemporalMemory\n",
    "from nupic.encoders.multi import  MultiEncoder\n",
    "from  nupic.encoders.scalar import ScalarEncoder\n",
    "from nupic.encoders.category import CategoryEncoder\n",
    "from nupic.algorithms.sdr_classifier import  SDRClassifier\n",
    "import csv \n",
    "from time import time\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        PARAMS_PATH =  (\"model_iot.yaml\")\n",
    "        with open(PARAMS_PATH, \"r\") as f:\n",
    "            modelParams = yaml.safe_load(f)[\"modelParams\"]   \n",
    "            spParams = modelParams[\"spParams\"]\n",
    "            tmParams = modelParams[\"tmParams\"]\n",
    "            clParams = modelParams[\"clParams\"]\n",
    "        sink_tap_Encoder = ScalarEncoder(name=\"sink_tap\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "        toilet_Encoder = ScalarEncoder(name=\"toilet\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "        shower_Encoder = ScalarEncoder(name=\"shower\", w=7, n=14, minval=0, maxval=1,forced=True)\n",
    "\n",
    "        baselineEncoder = ScalarEncoder(name = \"baseline\",w = 21, n = 2625,minval= 47,maxval=75,forced= True)\n",
    "\n",
    "        flowEncoder = ScalarEncoder(name=\"flow\", w=15, n=1350, minval=0, maxval=11,forced = True)\n",
    "        encodingWidth = (sink_tap_Encoder.getWidth()+flowEncoder.getWidth()+baselineEncoder.getWidth()\n",
    "                                +toilet_Encoder.getWidth()+flowEncoder.getWidth()+baselineEncoder.getWidth()\n",
    "                                +shower_Encoder.getWidth()+flowEncoder.getWidth()+baselineEncoder.getWidth())\n",
    "        sp = SpatialPooler(\n",
    "            inputDimensions=(encodingWidth,),\n",
    "            columnDimensions=(spParams[\"columnCount\"],),\n",
    "            potentialPct=spParams[\"potentialPct\"],\n",
    "            potentialRadius=encodingWidth,\n",
    "            globalInhibition=spParams[\"globalInhibition\"],\n",
    "            localAreaDensity=spParams[\"localAreaDensity\"],\n",
    "            numActiveColumnsPerInhArea=spParams[\"numActiveColumnsPerInhArea\"],\n",
    "            synPermInactiveDec=spParams[\"synPermInactiveDec\"],\n",
    "            synPermActiveInc=spParams[\"synPermActiveInc\"],\n",
    "            synPermConnected=spParams[\"synPermConnected\"],\n",
    "            boostStrength=spParams[\"boostStrength\"],\n",
    "            seed=spParams[\"seed\"],\n",
    "            wrapAround=True\n",
    "        )\n",
    "        tm = TemporalMemory(\n",
    "            columnDimensions=(tmParams[\"columnCount\"],),\n",
    "            cellsPerColumn=tmParams[\"cellsPerColumn\"],\n",
    "            activationThreshold=tmParams[\"activationThreshold\"],\n",
    "            initialPermanence=tmParams[\"initialPerm\"],\n",
    "            connectedPermanence=spParams[\"synPermConnected\"],\n",
    "            minThreshold=tmParams[\"minThreshold\"],\n",
    "            maxNewSynapseCount=tmParams[\"newSynapseCount\"],\n",
    "            permanenceIncrement=tmParams[\"permanenceInc\"],\n",
    "            permanenceDecrement=tmParams[\"permanenceDec\"],\n",
    "            predictedSegmentDecrement=tmParams[\"predictedSegmentDecrement\"],\n",
    "            maxSegmentsPerCell=tmParams[\"maxSegmentsPerCell\"],\n",
    "            maxSynapsesPerSegment=tmParams[\"maxSynapsesPerSegment\"],\n",
    "            seed=tmParams[\"seed\"]\n",
    "        )\n",
    "        classifier = SDRClassifier(\n",
    "            steps  = [1],alpha=clParams[\"alpha\"],verbosity= clParams[\"verbosity\"]\n",
    "        )\n",
    "        classifier1 = SDRClassifier(\n",
    "            steps  = [1],alpha=clParams[\"alpha\"],verbosity= clParams[\"verbosity\"]\n",
    "        )\n",
    "        classifier2 = SDRClassifier(\n",
    "            steps  = [1],alpha=clParams[\"alpha\"],verbosity= clParams[\"verbosity\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     def runLearning(numRecords):\n",
    "        classifier_counter = 0\n",
    "        learning_time = time()\n",
    "        with open(\"test.csv\", \"r\") as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            headers = reader.next()\n",
    "            reader.next()\n",
    "            reader.next()\n",
    "            progress = wg.IntProgress(min = 0,max = 1000,value = 0,description = \"Loading\",step = 1,bar_style='info')\n",
    "            number_iterations_widget = wg.IntSlider(min = 1000,max = 20000,value = 0,step =500,descroption=\"Number of iterations\",orientation='horizontal')\n",
    "            \n",
    "            display(progress,number_iterations_widget)\n",
    "            for count, record in enumerate(reader):\n",
    "                #print \"Count\",count\n",
    "                progress.value = count\n",
    "                \n",
    "                if count >= numRecords: break\n",
    "\n",
    "                # Convert data value string into float.\n",
    "                sink_tap_value = float(record[2]) # device 1\n",
    "                toilet_value = float(record[3]) #device 2\n",
    "                shower__value = float(record[4]) # device 3\n",
    "\n",
    "                 # event_value_7 = float(record[8]) # device 7\n",
    "                baseline_all = float(record[6])\n",
    "                flow_value  = float(record[0])\n",
    "                # To encode, we need to provide zero-filled numpy arrays for the encoders\n",
    "                # to populate.\n",
    "                eventBits = numpy.zeros(sink_tap_Encoder.getWidth())\n",
    "                eventBits_2 = numpy.zeros(toilet_Encoder.getWidth())\n",
    "                eventBits_3 = numpy.zeros(shower_Encoder.getWidth())\n",
    "\n",
    "                baseline_Bits = numpy.zeros(baselineEncoder.getWidth())\n",
    "                flowBits = numpy.zeros(flowEncoder.getWidth())\n",
    "\n",
    "                 # Now we call the encoders to create bit representations for each value.\n",
    "                sink_tap_Encoder.encodeIntoArray(sink_tap_value, eventBits)\n",
    "                toilet_Encoder.encodeIntoArray(toilet_value,eventBits_3)\n",
    "                shower_Encoder.encodeIntoArray(shower__value,eventBits_2) \n",
    "\n",
    "                baselineEncoder.encodeIntoArray(baseline_all,baseline_Bits)\n",
    "                flowEncoder.encodeIntoArray(flow_value, flowBits)\n",
    "\n",
    "                # Concatenate all these encodings into one large encoding for Spatial\n",
    "                 # Pooling.\n",
    "                encoding = numpy.concatenate(\n",
    "                    [eventBits,flowBits,baseline_Bits,eventBits_2,flowBits,baseline_Bits,eventBits_3,flowBits,baseline_Bits]\n",
    "                )\n",
    "\n",
    "                # Create an array to represent active columns, all initially zero. This\n",
    "                 # will be populated by the compute method below. It must have the same\n",
    "                 # dimensions as the Spatial Pooler.\n",
    "                activeColumns = numpy.zeros(spParams[\"columnCount\"])\n",
    "                 # activeColumns1 = numpy.zeros(spParams[\"columnCount\"])\n",
    "\n",
    "                 # Execute Spatial Pooling algorithm over input space.\n",
    "\n",
    "                sp.compute(encoding,True,activeColumns)\n",
    "\n",
    "                # sp.compute(encoding1, True, activeColumns)\n",
    "\n",
    "                activeColumnIndices = numpy.nonzero(activeColumns)[0]\n",
    "\n",
    "                 # Execute Temporal Memory algorithm over active mini-columns.\n",
    "                tm.compute(activeColumnIndices, learn=True)\n",
    "\n",
    "                activeCells = tm.getActiveCells()\n",
    "\n",
    "                # Get the bucket info for this input value for classification.\n",
    "                bucketIdx_sink_tap  =  sink_tap_Encoder.getBucketIndices(sink_tap_value)[0] \n",
    "                bucketIdx_toilet = toilet_Encoder.getBucketIndices(toilet_value)[0]\n",
    "                bucketIdx_shower = shower_Encoder.getBucketIndices(shower__value)[0]\n",
    "\n",
    "                # Run classifier to translate active cells back to scalar value.\n",
    "                classifierResult = classifier.compute(\n",
    "                    recordNum=classifier_counter,\n",
    "                    patternNZ=activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": bucketIdx_sink_tap,\n",
    "                        \"actValue\": sink_tap_value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "                classifierResult1 = classifier1.compute(\n",
    "                    recordNum=classifier_counter,\n",
    "                    patternNZ=activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": bucketIdx_toilet,\n",
    "                        \"actValue\": toilet_value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "\n",
    "                classifierResult2 = classifier2.compute(\n",
    "                    recordNum=classifier_counter,\n",
    "                    patternNZ=activeCells,\n",
    "                    classification={\n",
    "                        \"bucketIdx\": bucketIdx_shower,\n",
    "                        \"actValue\": shower__value\n",
    "                    },\n",
    "                    learn=True,\n",
    "                    infer=False\n",
    "                )\n",
    "                classifier_counter += 1\n",
    "                learning_time_end = time()\n",
    "\n",
    "           #     print \"Time\",(learning_time - learning_time_end)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLearning(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
